{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOHzIl4oqAreUgXdglqcSoL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rc4yGL55HuEI","executionInfo":{"status":"ok","timestamp":1734432340812,"user_tz":-420,"elapsed":19541,"user":{"displayName":"Minh Khải","userId":"17162546248965680877"}},"outputId":"a3d65ba1-6496-4320-a0a0-4f12c43c26a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/MARL-Project"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ei3gU2euIgcu","executionInfo":{"status":"ok","timestamp":1734432340812,"user_tz":-420,"elapsed":4,"user":{"displayName":"Minh Khải","userId":"17162546248965680877"}},"outputId":"2c42d725-f023-47ee-b789-4659060dcf65"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/MARL-Project\n"]}]},{"cell_type":"code","source":["!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8F2Gec8HIhBQ","executionInfo":{"status":"ok","timestamp":1734432377510,"user_tz":-420,"elapsed":36701,"user":{"displayName":"Minh Khải","userId":"17162546248965680877"}},"outputId":"4459baf5-dbf4-4962-e61e-11726c8264da"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/Farama-Foundation/MAgent2 (from -r requirements.txt (line 1))\n","  Cloning https://github.com/Farama-Foundation/MAgent2 to /tmp/pip-req-build-f8ydq69_\n","  Running command git clone --filter=blob:none --quiet https://github.com/Farama-Foundation/MAgent2 /tmp/pip-req-build-f8ydq69_\n","  Resolved https://github.com/Farama-Foundation/MAgent2 to commit b2ddd49445368cf85d4d4e1edcddae2e28aa1406\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (4.10.0.84)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.5.1+cu121)\n","Requirement already satisfied: numpy<2.0,>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from magent2==0.3.3->-r requirements.txt (line 1)) (1.26.4)\n","Requirement already satisfied: pygame>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from magent2==0.3.3->-r requirements.txt (line 1)) (2.6.1)\n","Collecting pettingzoo>=1.23.1 (from magent2==0.3.3->-r requirements.txt (line 1))\n","  Downloading pettingzoo-1.24.3-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 3)) (1.3.0)\n","Collecting gymnasium>=0.28.0 (from pettingzoo>=1.23.1->magent2==0.3.3->-r requirements.txt (line 1))\n","  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 3)) (3.0.2)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo>=1.23.1->magent2==0.3.3->-r requirements.txt (line 1)) (3.1.0)\n","Collecting farama-notifications>=0.0.1 (from gymnasium>=0.28.0->pettingzoo>=1.23.1->magent2==0.3.3->-r requirements.txt (line 1))\n","  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n","Downloading pettingzoo-1.24.3-py3-none-any.whl (847 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m847.8/847.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n","Building wheels for collected packages: magent2\n","  Building wheel for magent2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for magent2: filename=magent2-0.3.3-cp310-cp310-linux_x86_64.whl size=1696077 sha256=b08fdf9045f86c0a5671710da7f11110cd82cb55f70dc0298fc98d8dc411346b\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-fqb11o4q/wheels/e4/8e/bf/51a30bc4038546e23b81c9fb513fe6a8fd916e5a9c5f4291d5\n","Successfully built magent2\n","Installing collected packages: farama-notifications, gymnasium, pettingzoo, magent2\n","Successfully installed farama-notifications-0.0.4 gymnasium-1.0.0 magent2-0.3.3 pettingzoo-1.24.3\n"]}]},{"cell_type":"code","source":["!python trainer.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vFk-QGgzIgZx","executionInfo":{"status":"ok","timestamp":1734433994327,"user_tz":-420,"elapsed":1445710,"user":{"displayName":"Minh Khải","userId":"17162546248965680877"}},"outputId":"d02f9dfa-787d-4b58-d88a-40fbd810c64a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/MARL-Project/trainer.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  actions = torch.tensor(actions, dtype=torch.long).to(self.device)\n","/content/drive/MyDrive/MARL-Project/trainer.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  rewards = torch.tensor(rewards, dtype=torch.float32).to(self.device)\n","/content/drive/MyDrive/MARL-Project/trainer.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  dones = torch.tensor(dones, dtype=torch.float32).to(self.device)\n","Episode 0, Epsilon: 1.00, Total Reward: -3240.9551184549928, Steps: 159719, Max Reward: -7.16000044811517, Avg Reward: -40.01\n","Episode 1, Epsilon: 0.97, Total Reward: -3189.86011621356, Steps: 158738, Max Reward: -27.160000969655812, Avg Reward: -39.38\n","Episode 2, Epsilon: 0.94, Total Reward: -3026.2351094437763, Steps: 159466, Max Reward: -4.4150001695379615, Avg Reward: -37.36\n","Episode 3, Epsilon: 0.91, Total Reward: -2983.9351073941216, Steps: 161036, Max Reward: -27.045001014135778, Avg Reward: -36.84\n","Episode 4, Epsilon: 0.89, Total Reward: -2907.6251036757603, Steps: 159708, Max Reward: -18.375000670552254, Avg Reward: -35.90\n","Episode 5, Epsilon: 0.86, Total Reward: -2850.1201008195058, Steps: 160006, Max Reward: -11.350000409409404, Avg Reward: -35.19\n","Episode 6, Epsilon: 0.83, Total Reward: -2804.6550987567753, Steps: 158431, Max Reward: -15.255000561475754, Avg Reward: -34.63\n","Episode 7, Epsilon: 0.81, Total Reward: -2762.3650960559025, Steps: 161304, Max Reward: -26.465000929310918, Avg Reward: -34.10\n","Episode 8, Epsilon: 0.78, Total Reward: -2627.6000906107947, Steps: 160904, Max Reward: -9.960000350140035, Avg Reward: -32.44\n","Episode 9, Epsilon: 0.76, Total Reward: -2543.975087856874, Steps: 159773, Max Reward: -10.045000337064266, Avg Reward: -31.41\n","Episode 10, Epsilon: 0.74, Total Reward: -2506.815085894428, Steps: 161302, Max Reward: -24.880000863224268, Avg Reward: -30.95\n","Episode 11, Epsilon: 0.72, Total Reward: -2126.435082941316, Steps: 141520, Max Reward: -1.1800000676885247, Avg Reward: -26.25\n","Episode 12, Epsilon: 0.69, Total Reward: -2084.500085032545, Steps: 120637, Max Reward: -5.900001005269587, Avg Reward: -25.73\n","Episode 13, Epsilon: 0.67, Total Reward: -1360.6050614174455, Steps: 82920, Max Reward: 8.624999235384166, Avg Reward: -16.80\n","Episode 14, Epsilon: 0.65, Total Reward: -2006.800078831613, Steps: 119957, Max Reward: 24.099998894147575, Avg Reward: -24.78\n","Episode 15, Epsilon: 0.63, Total Reward: -1891.300076157786, Steps: 116922, Max Reward: -2.5000009993091226, Avg Reward: -23.35\n","Episode 16, Epsilon: 0.61, Total Reward: -1944.0000745654106, Steps: 129462, Max Reward: 1.9999988861382008, Avg Reward: -24.00\n","Episode 17, Epsilon: 0.60, Total Reward: -1736.3000704003498, Steps: 105378, Max Reward: 5.499999041669071, Avg Reward: -21.44\n","Episode 18, Epsilon: 0.58, Total Reward: -1791.7000694377348, Steps: 125144, Max Reward: 3.8999989787116647, Avg Reward: -22.12\n","Episode 19, Epsilon: 0.56, Total Reward: -1685.55506758485, Steps: 111633, Max Reward: 22.699998867698014, Avg Reward: -20.81\n","Episode 20, Epsilon: 0.54, Total Reward: -873.2500423099846, Steps: 67959, Max Reward: 21.08499932475388, Avg Reward: -10.78\n","Episode 21, Epsilon: 0.53, Total Reward: -1418.595058743842, Steps: 97999, Max Reward: 30.704998966306448, Avg Reward: -17.51\n","Episode 22, Epsilon: 0.51, Total Reward: -578.4100326728076, Steps: 58091, Max Reward: 31.689999443478882, Avg Reward: -7.14\n","Episode 23, Epsilon: 0.50, Total Reward: -1498.5000590505078, Steps: 100451, Max Reward: 24.699999132193625, Avg Reward: -18.50\n","Episode 24, Epsilon: 0.48, Total Reward: -1493.3000567490235, Steps: 114293, Max Reward: 14.899999170564115, Avg Reward: -18.44\n","Episode 25, Epsilon: 0.47, Total Reward: -1476.4000549577177, Steps: 103554, Max Reward: 9.999999228864908, Avg Reward: -18.23\n","Episode 26, Epsilon: 0.45, Total Reward: -1455.7000522492453, Steps: 127298, Max Reward: 45.2999989753589, Avg Reward: -17.97\n","Episode 27, Epsilon: 0.44, Total Reward: -63.545016451738775, Steps: 35014, Max Reward: 39.84999960009009, Avg Reward: -0.78\n","Episode 28, Epsilon: 0.43, Total Reward: -296.06502247974277, Steps: 50366, Max Reward: 19.434999627061188, Avg Reward: -3.66\n","Episode 29, Epsilon: 0.41, Total Reward: -1450.6800470165908, Steps: 133945, Max Reward: 19.9999992325902, Avg Reward: -17.91\n","Episode 30, Epsilon: 0.40, Total Reward: -1297.3000458208844, Steps: 128716, Max Reward: 8.999999409541488, Avg Reward: -16.02\n","Episode 31, Epsilon: 0.39, Total Reward: -1305.1000439422205, Steps: 129842, Max Reward: 14.199999386444688, Avg Reward: -16.11\n","Episode 32, Epsilon: 0.38, Total Reward: -1168.5700409393758, Steps: 121920, Max Reward: 2.399999439716339, Avg Reward: -14.43\n","Episode 33, Epsilon: 0.37, Total Reward: -1191.9000408137217, Steps: 116438, Max Reward: 6.699999389238656, Avg Reward: -14.71\n","Episode 34, Epsilon: 0.36, Total Reward: -1176.380039206706, Steps: 123709, Max Reward: 11.799999378621578, Avg Reward: -14.52\n","Episode 35, Epsilon: 0.34, Total Reward: -1078.6400381587446, Steps: 127356, Max Reward: 3.3999994322657585, Avg Reward: -13.32\n","Episode 36, Epsilon: 0.33, Total Reward: -1245.5000357953832, Steps: 141579, Max Reward: -6.800000445917249, Avg Reward: -15.38\n","Episode 37, Epsilon: 0.32, Total Reward: -1210.8000343311578, Steps: 145447, Max Reward: 3.5999995190650225, Avg Reward: -14.95\n","Episode 38, Epsilon: 0.31, Total Reward: -1089.3400321090594, Steps: 142079, Max Reward: 0.2999995844438672, Avg Reward: -13.45\n","Episode 39, Epsilon: 0.30, Total Reward: -882.720032799989, Steps: 115331, Max Reward: 10.399999553337693, Avg Reward: -10.90\n","Episode 40, Epsilon: 0.30, Total Reward: -959.0900319712237, Steps: 116071, Max Reward: 14.489999879151583, Avg Reward: -11.84\n","Episode 41, Epsilon: 0.29, Total Reward: -1002.9000307386741, Steps: 133753, Max Reward: 0.19999959133565426, Avg Reward: -12.38\n","Episode 42, Epsilon: 0.28, Total Reward: -1068.6000286582857, Steps: 147372, Max Reward: 0.1999996304512024, Avg Reward: -13.19\n","Episode 43, Epsilon: 0.27, Total Reward: -798.2150286948308, Steps: 110635, Max Reward: 16.899999362416565, Avg Reward: -9.85\n","Episode 44, Epsilon: 0.26, Total Reward: -824.2650268832222, Steps: 116639, Max Reward: 6.2999996012076735, Avg Reward: -10.18\n","Episode 45, Epsilon: 0.25, Total Reward: -754.800027212128, Steps: 114850, Max Reward: 9.499999486841261, Avg Reward: -9.32\n","Episode 46, Epsilon: 0.25, Total Reward: -978.000025017187, Steps: 144048, Max Reward: 4.599999584257603, Avg Reward: -12.07\n","Early stopping at episode 47\n","Thời gian thực thi: 1440.574541 giây\n"]}]},{"cell_type":"code","source":["!python eval.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AV4N2k0EIgW5","executionInfo":{"status":"ok","timestamp":1734436035256,"user_tz":-420,"elapsed":1952007,"user":{"displayName":"Minh Khải","userId":"17162546248965680877"}},"outputId":"c7a3616a-7af9-4531-e9e2-6bb46579f0f3"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["====================\n","Eval with random policy\n","/usr/local/lib/python3.10/dist-packages/pettingzoo/utils/conversions.py:289: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.\n","  warnings.warn(\n","  0% 0/30 [00:00<?, ?it/s]Done recording pretrained agents\n","  3% 1/30 [00:23<11:21, 23.49s/it]Done recording pretrained agents\n","  7% 2/30 [00:44<10:10, 21.80s/it]Done recording pretrained agents\n"," 10% 3/30 [01:05<09:48, 21.78s/it]Done recording pretrained agents\n"," 13% 4/30 [01:30<09:55, 22.91s/it]Done recording pretrained agents\n"," 17% 5/30 [01:51<09:15, 22.20s/it]Done recording pretrained agents\n"," 20% 6/30 [02:13<08:50, 22.11s/it]Done recording pretrained agents\n"," 23% 7/30 [02:33<08:14, 21.48s/it]Done recording pretrained agents\n"," 27% 8/30 [02:54<07:45, 21.17s/it]Done recording pretrained agents\n"," 30% 9/30 [03:15<07:24, 21.17s/it]Done recording pretrained agents\n"," 33% 10/30 [03:38<07:17, 21.87s/it]Done recording pretrained agents\n"," 37% 11/30 [04:02<07:04, 22.32s/it]Done recording pretrained agents\n"," 40% 12/30 [04:20<06:22, 21.26s/it]Done recording pretrained agents\n"," 43% 13/30 [04:45<06:18, 22.24s/it]Done recording pretrained agents\n"," 47% 14/30 [05:07<05:57, 22.34s/it]Done recording pretrained agents\n"," 50% 15/30 [05:28<05:28, 21.89s/it]Done recording pretrained agents\n"," 53% 16/30 [05:54<05:20, 22.91s/it]Done recording pretrained agents\n"," 57% 17/30 [06:15<04:50, 22.35s/it]Done recording pretrained agents\n"," 60% 18/30 [06:37<04:27, 22.30s/it]Done recording pretrained agents\n"," 63% 19/30 [06:59<04:05, 22.33s/it]Done recording pretrained agents\n"," 67% 20/30 [07:21<03:42, 22.24s/it]Done recording pretrained agents\n"," 70% 21/30 [07:40<03:11, 21.28s/it]Done recording pretrained agents\n"," 73% 22/30 [07:59<02:44, 20.51s/it]Done recording pretrained agents\n"," 77% 23/30 [08:20<02:25, 20.77s/it]Done recording pretrained agents\n"," 80% 24/30 [08:42<02:06, 21.04s/it]Done recording pretrained agents\n"," 83% 25/30 [09:03<01:45, 21.02s/it]Done recording pretrained agents\n"," 87% 26/30 [09:24<01:23, 20.95s/it]Done recording pretrained agents\n"," 90% 27/30 [09:48<01:05, 21.86s/it]Done recording pretrained agents\n"," 93% 28/30 [10:12<00:44, 22.46s/it]Done recording pretrained agents\n"," 97% 29/30 [10:34<00:22, 22.45s/it]Done recording pretrained agents\n","100% 30/30 [10:54<00:00, 21.81s/it]\n","{'winrate_red': 0.0, 'winrate_blue': 1.0, 'average_rewards_red': -5.544329413841, 'average_rewards_blue': 4.091020575672036}\n","====================\n","Eval with trained policy\n","/usr/local/lib/python3.10/dist-packages/pettingzoo/utils/conversions.py:289: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.\n","  warnings.warn(\n","  0% 0/30 [00:00<?, ?it/s]Done recording pretrained agents\n","  3% 1/30 [00:13<06:21, 13.17s/it]Done recording pretrained agents\n","  7% 2/30 [00:28<06:42, 14.37s/it]Done recording pretrained agents\n"," 10% 3/30 [00:43<06:34, 14.60s/it]Done recording pretrained agents\n"," 13% 4/30 [00:56<06:03, 13.98s/it]Done recording pretrained agents\n"," 17% 5/30 [01:09<05:43, 13.75s/it]Done recording pretrained agents\n"," 20% 6/30 [01:24<05:35, 13.99s/it]Done recording pretrained agents\n"," 23% 7/30 [01:37<05:16, 13.75s/it]Done recording pretrained agents\n"," 27% 8/30 [01:52<05:12, 14.22s/it]Done recording pretrained agents\n"," 30% 9/30 [02:09<05:16, 15.05s/it]Done recording pretrained agents\n"," 33% 10/30 [02:27<05:18, 15.93s/it]Done recording pretrained agents\n"," 37% 11/30 [02:41<04:53, 15.45s/it]Done recording pretrained agents\n"," 40% 12/30 [02:57<04:40, 15.58s/it]Done recording pretrained agents\n"," 43% 13/30 [03:12<04:20, 15.32s/it]Done recording pretrained agents\n"," 47% 14/30 [03:26<04:00, 15.04s/it]Done recording pretrained agents\n"," 50% 15/30 [03:45<04:03, 16.21s/it]Done recording pretrained agents\n"," 53% 16/30 [04:03<03:56, 16.86s/it]Done recording pretrained agents\n"," 57% 17/30 [04:18<03:28, 16.03s/it]Done recording pretrained agents\n"," 60% 18/30 [04:31<03:01, 15.15s/it]Done recording pretrained agents\n"," 63% 19/30 [04:44<02:38, 14.45s/it]Done recording pretrained agents\n"," 67% 20/30 [04:57<02:22, 14.27s/it]Done recording pretrained agents\n"," 70% 21/30 [05:12<02:08, 14.33s/it]Done recording pretrained agents\n"," 73% 22/30 [05:26<01:53, 14.22s/it]Done recording pretrained agents\n"," 77% 23/30 [05:42<01:42, 14.71s/it]Done recording pretrained agents\n"," 80% 24/30 [06:00<01:34, 15.80s/it]Done recording pretrained agents\n"," 83% 25/30 [06:14<01:16, 15.39s/it]Done recording pretrained agents\n"," 87% 26/30 [06:28<00:58, 14.74s/it]Done recording pretrained agents\n"," 90% 27/30 [06:42<00:43, 14.51s/it]Done recording pretrained agents\n"," 93% 28/30 [06:55<00:28, 14.16s/it]Done recording pretrained agents\n"," 97% 29/30 [07:10<00:14, 14.45s/it]Done recording pretrained agents\n","100% 30/30 [07:22<00:00, 14.75s/it]\n","{'winrate_red': 0.0, 'winrate_blue': 1.0, 'average_rewards_red': 1.7227530779535478, 'average_rewards_blue': 4.596493812929839}\n","====================\n","Eval with final trained policy\n","  0% 0/30 [00:00<?, ?it/s]Done recording pretrained agents\n","  3% 1/30 [00:25<12:24, 25.67s/it]Done recording pretrained agents\n","  7% 2/30 [00:54<12:55, 27.69s/it]Done recording pretrained agents\n"," 10% 3/30 [01:23<12:40, 28.18s/it]Done recording pretrained agents\n"," 13% 4/30 [01:51<12:12, 28.19s/it]Done recording pretrained agents\n"," 17% 5/30 [02:19<11:41, 28.06s/it]Done recording pretrained agents\n"," 20% 6/30 [02:47<11:14, 28.10s/it]Done recording pretrained agents\n"," 23% 7/30 [03:17<11:01, 28.75s/it]Done recording pretrained agents\n"," 27% 8/30 [03:46<10:30, 28.65s/it]Done recording pretrained agents\n"," 30% 9/30 [04:14<09:59, 28.56s/it]Done recording pretrained agents\n"," 33% 10/30 [04:43<09:36, 28.81s/it]Done recording pretrained agents\n"," 37% 11/30 [05:12<09:05, 28.69s/it]Done recording pretrained agents\n"," 40% 12/30 [05:40<08:32, 28.48s/it]Done recording pretrained agents\n"," 43% 13/30 [06:09<08:05, 28.56s/it]Done recording pretrained agents\n"," 47% 14/30 [06:39<07:43, 28.95s/it]Done recording pretrained agents\n"," 50% 15/30 [07:07<07:09, 28.66s/it]Done recording pretrained agents\n"," 53% 16/30 [07:36<06:44, 28.90s/it]Done recording pretrained agents\n"," 57% 17/30 [08:05<06:14, 28.82s/it]Done recording pretrained agents\n"," 60% 18/30 [08:33<05:45, 28.80s/it]Done recording pretrained agents\n"," 63% 19/30 [09:03<05:18, 28.96s/it]Done recording pretrained agents\n"," 67% 20/30 [09:31<04:48, 28.81s/it]Done recording pretrained agents\n"," 70% 21/30 [09:59<04:17, 28.62s/it]Done recording pretrained agents\n"," 73% 22/30 [10:26<03:43, 28.00s/it]Done recording pretrained agents\n"," 77% 23/30 [10:56<03:19, 28.52s/it]Done recording pretrained agents\n"," 80% 24/30 [11:24<02:50, 28.46s/it]Done recording pretrained agents\n"," 83% 25/30 [11:52<02:21, 28.32s/it]Done recording pretrained agents\n"," 87% 26/30 [12:21<01:54, 28.62s/it]Done recording pretrained agents\n"," 90% 27/30 [12:49<01:25, 28.39s/it]Done recording pretrained agents\n"," 93% 28/30 [13:17<00:56, 28.11s/it]Done recording pretrained agents\n"," 97% 29/30 [13:44<00:27, 28.00s/it]Done recording pretrained agents\n","100% 30/30 [14:10<00:00, 28.34s/it]\n","{'winrate_red': 0.0, 'winrate_blue': 1.0, 'average_rewards_red': 1.017995837927938, 'average_rewards_blue': 3.528419752317814}\n","====================\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"z5cD2XvbU897"},"execution_count":null,"outputs":[]}]}