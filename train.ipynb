{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOHzIl4oqAreUgXdglqcSoL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rc4yGL55HuEI","executionInfo":{"status":"ok","timestamp":1734439650086,"user_tz":-420,"elapsed":23912,"user":{"displayName":"Minh Khải","userId":"17162546248965680877"}},"outputId":"dbbf9b34-d72c-4323-e421-e6bbca4e4035"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/MARL-Project"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ei3gU2euIgcu","executionInfo":{"status":"ok","timestamp":1734439650086,"user_tz":-420,"elapsed":4,"user":{"displayName":"Minh Khải","userId":"17162546248965680877"}},"outputId":"55f4ebe3-c304-4cbb-db80-b5740ff62a49"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/MARL-Project\n"]}]},{"cell_type":"code","source":["!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8F2Gec8HIhBQ","executionInfo":{"status":"ok","timestamp":1734439688804,"user_tz":-420,"elapsed":38721,"user":{"displayName":"Minh Khải","userId":"17162546248965680877"}},"outputId":"0e7befb0-bad4-46f7-95ee-10a1ea6a36c0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/Farama-Foundation/MAgent2 (from -r requirements.txt (line 1))\n","  Cloning https://github.com/Farama-Foundation/MAgent2 to /tmp/pip-req-build-ixkkcns2\n","  Running command git clone --filter=blob:none --quiet https://github.com/Farama-Foundation/MAgent2 /tmp/pip-req-build-ixkkcns2\n","  Resolved https://github.com/Farama-Foundation/MAgent2 to commit b2ddd49445368cf85d4d4e1edcddae2e28aa1406\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (4.10.0.84)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.5.1+cu121)\n","Requirement already satisfied: numpy<2.0,>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from magent2==0.3.3->-r requirements.txt (line 1)) (1.26.4)\n","Requirement already satisfied: pygame>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from magent2==0.3.3->-r requirements.txt (line 1)) (2.6.1)\n","Collecting pettingzoo>=1.23.1 (from magent2==0.3.3->-r requirements.txt (line 1))\n","  Downloading pettingzoo-1.24.3-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 3)) (1.3.0)\n","Collecting gymnasium>=0.28.0 (from pettingzoo>=1.23.1->magent2==0.3.3->-r requirements.txt (line 1))\n","  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 3)) (3.0.2)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo>=1.23.1->magent2==0.3.3->-r requirements.txt (line 1)) (3.1.0)\n","Collecting farama-notifications>=0.0.1 (from gymnasium>=0.28.0->pettingzoo>=1.23.1->magent2==0.3.3->-r requirements.txt (line 1))\n","  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n","Downloading pettingzoo-1.24.3-py3-none-any.whl (847 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m847.8/847.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n","Building wheels for collected packages: magent2\n","  Building wheel for magent2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for magent2: filename=magent2-0.3.3-cp310-cp310-linux_x86_64.whl size=1696073 sha256=b45c33b54ea478cd3dc09f064b4ab8322a1b44c1781971e24eaeb2b81fa975a9\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ygpv4a4w/wheels/e4/8e/bf/51a30bc4038546e23b81c9fb513fe6a8fd916e5a9c5f4291d5\n","Successfully built magent2\n","Installing collected packages: farama-notifications, gymnasium, pettingzoo, magent2\n","Successfully installed farama-notifications-0.0.4 gymnasium-1.0.0 magent2-0.3.3 pettingzoo-1.24.3\n"]}]},{"cell_type":"code","source":["!python trainer.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vFk-QGgzIgZx","executionInfo":{"status":"ok","timestamp":1734441331186,"user_tz":-420,"elapsed":1599131,"user":{"displayName":"Minh Khải","userId":"17162546248965680877"}},"outputId":"75210203-78e3-4582-b264-27ad9d82c693"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/MARL-Project/trainer.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  actions = torch.tensor(actions, dtype=torch.long).to(self.device)\n","/content/drive/MyDrive/MARL-Project/trainer.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  rewards = torch.tensor(rewards, dtype=torch.float32).to(self.device)\n","/content/drive/MyDrive/MARL-Project/trainer.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  dones = torch.tensor(dones, dtype=torch.float32).to(self.device)\n","Episode 0, Epsilon: 1.00, Total Reward: -3268.4701199727133, Steps: 160850, Max Reward: -31.6600011754781, Avg Reward: -40.35\n","Episode 1, Epsilon: 0.97, Total Reward: -3160.935113750398, Steps: 160192, Max Reward: -6.260000237263739, Avg Reward: -39.02\n","Episode 2, Epsilon: 0.94, Total Reward: -3004.20510791149, Steps: 158049, Max Reward: -4.485000190325081, Avg Reward: -37.09\n","Episode 3, Epsilon: 0.91, Total Reward: -2983.545107640326, Steps: 161358, Max Reward: -13.345000509172678, Avg Reward: -36.83\n","Episode 4, Epsilon: 0.89, Total Reward: -2900.510103442706, Steps: 159786, Max Reward: -6.990000255405903, Avg Reward: -35.81\n","Episode 5, Epsilon: 0.86, Total Reward: -2801.4350992226973, Steps: 159424, Max Reward: -2.3350001024082303, Avg Reward: -34.59\n","Episode 6, Epsilon: 0.83, Total Reward: -2617.0300917960703, Steps: 156778, Max Reward: -2.6700000977143645, Avg Reward: -32.31\n","Episode 7, Epsilon: 0.81, Total Reward: -2692.260094497353, Steps: 160116, Max Reward: -3.260000117123127, Avg Reward: -33.24\n","Episode 8, Epsilon: 0.78, Total Reward: -2629.1000908548012, Steps: 161244, Max Reward: -2.505000094883144, Avg Reward: -32.46\n","Episode 9, Epsilon: 0.76, Total Reward: -2418.490083879791, Steps: 155412, Max Reward: -4.240000190213323, Avg Reward: -29.86\n","Episode 10, Epsilon: 0.74, Total Reward: -2213.320076451637, Steps: 153180, Max Reward: -2.285000091418624, Avg Reward: -27.32\n","Episode 11, Epsilon: 0.72, Total Reward: -2284.4850787473843, Steps: 157422, Max Reward: -3.1500001065433025, Avg Reward: -28.20\n","Episode 12, Epsilon: 0.69, Total Reward: -2016.9400733904913, Steps: 144755, Max Reward: -1.8400000697001815, Avg Reward: -24.90\n","Episode 13, Epsilon: 0.67, Total Reward: -1954.9500737851486, Steps: 143691, Max Reward: -1.4900001026690006, Avg Reward: -24.14\n","Episode 14, Epsilon: 0.65, Total Reward: -1776.6550724487752, Steps: 113053, Max Reward: 3.2999989027157426, Avg Reward: -21.93\n","Episode 15, Epsilon: 0.63, Total Reward: -1896.4300757870078, Steps: 128891, Max Reward: 4.299998990260065, Avg Reward: -23.41\n","Episode 16, Epsilon: 0.61, Total Reward: -1710.355070937425, Steps: 99216, Max Reward: 12.299998802132905, Avg Reward: -21.12\n","Episode 17, Epsilon: 0.60, Total Reward: -1718.7250703396276, Steps: 100605, Max Reward: 26.39999893680215, Avg Reward: -21.22\n","Episode 18, Epsilon: 0.58, Total Reward: -535.9700338151306, Steps: 56611, Max Reward: 30.37499936390668, Avg Reward: -6.62\n","Episode 19, Epsilon: 0.56, Total Reward: -1599.7350648446009, Steps: 93548, Max Reward: 17.89999905321747, Avg Reward: -19.75\n","Episode 20, Epsilon: 0.54, Total Reward: -1626.130064963363, Steps: 91222, Max Reward: 11.799998981878161, Avg Reward: -20.08\n","Episode 21, Epsilon: 0.53, Total Reward: -110.59001879952848, Steps: 30561, Max Reward: 30.20999967493117, Avg Reward: -1.37\n","Episode 22, Epsilon: 0.51, Total Reward: -868.4450409952551, Steps: 62622, Max Reward: 17.324999326840043, Avg Reward: -10.72\n","Episode 23, Epsilon: 0.50, Total Reward: -3.830015351064503, Steps: 26973, Max Reward: 35.479999710805714, Avg Reward: -0.05\n","Episode 24, Epsilon: 0.48, Total Reward: -1377.1150543689728, Steps: 85217, Max Reward: 15.204999869689345, Avg Reward: -17.00\n","Episode 25, Epsilon: 0.47, Total Reward: 110.49498831946403, Steps: 21252, Max Reward: 27.7049997812137, Avg Reward: 1.36\n","Episode 26, Epsilon: 0.45, Total Reward: -1346.520052808337, Steps: 93196, Max Reward: 34.299999124370515, Avg Reward: -16.62\n","Episode 27, Epsilon: 0.44, Total Reward: 216.95499152503908, Steps: 16297, Max Reward: 41.94999975524843, Avg Reward: 2.68\n","Episode 28, Epsilon: 0.43, Total Reward: 228.09999202471226, Steps: 16719, Max Reward: 29.734999774955213, Avg Reward: 2.82\n","Episode 29, Epsilon: 0.41, Total Reward: -1202.6150466362014, Steps: 84919, Max Reward: 11.899999354965985, Avg Reward: -14.85\n","Episode 30, Epsilon: 0.40, Total Reward: 245.30499267950654, Steps: 14779, Max Reward: 33.904999792575836, Avg Reward: 3.03\n","Episode 31, Epsilon: 0.39, Total Reward: 283.38999370019883, Steps: 11543, Max Reward: 19.33499985281378, Avg Reward: 3.50\n","Episode 32, Epsilon: 0.38, Total Reward: 112.77498927153647, Steps: 20885, Max Reward: 22.069999766536057, Avg Reward: 1.39\n","Episode 33, Epsilon: 0.37, Total Reward: -370.14002301637083, Steps: 46333, Max Reward: 21.169999603182077, Avg Reward: -4.57\n","Episode 34, Epsilon: 0.36, Total Reward: -862.1050351047888, Steps: 74002, Max Reward: 5.594999592751265, Avg Reward: -10.64\n","Episode 35, Epsilon: 0.34, Total Reward: -41.7450140286237, Steps: 30533, Max Reward: 15.35499978158623, Avg Reward: -0.52\n","Episode 36, Epsilon: 0.33, Total Reward: -1005.3000372787938, Steps: 85366, Max Reward: 0.09999959263950586, Avg Reward: -12.41\n","Episode 37, Epsilon: 0.32, Total Reward: 307.94499470759183, Steps: 10887, Max Reward: 23.844999838620424, Avg Reward: 3.80\n","Episode 38, Epsilon: 0.31, Total Reward: -802.7050314927474, Steps: 77391, Max Reward: 7.694999662227929, Avg Reward: -9.91\n","Episode 39, Epsilon: 0.30, Total Reward: 319.78499501477927, Steps: 10053, Max Reward: 19.78499989118427, Avg Reward: 3.95\n","Episode 40, Epsilon: 0.30, Total Reward: 322.56999507080764, Steps: 10459, Max Reward: 24.089999879710376, Avg Reward: 3.98\n","Episode 41, Epsilon: 0.29, Total Reward: 316.6249948190525, Steps: 10569, Max Reward: 24.279999882914126, Avg Reward: 3.91\n","Episode 42, Epsilon: 0.28, Total Reward: 331.50499538332224, Steps: 9823, Max Reward: 23.604999852366745, Avg Reward: 4.09\n","Episode 43, Epsilon: 0.27, Total Reward: 267.9549939809367, Steps: 13844, Max Reward: 18.054999832063913, Avg Reward: 3.31\n","Episode 44, Epsilon: 0.26, Total Reward: 318.8749950286001, Steps: 10279, Max Reward: 24.974999868310988, Avg Reward: 3.94\n","Episode 45, Epsilon: 0.25, Total Reward: 333.59999549388885, Steps: 9793, Max Reward: 19.499999877996743, Avg Reward: 4.12\n","Episode 46, Epsilon: 0.25, Total Reward: 274.63999430742115, Steps: 14494, Max Reward: 23.33999985270202, Avg Reward: 3.39\n","Episode 47, Epsilon: 0.24, Total Reward: 338.55999554973096, Steps: 9824, Max Reward: 19.519999877549708, Avg Reward: 4.18\n","Episode 48, Epsilon: 0.23, Total Reward: 337.6999956415966, Steps: 9979, Max Reward: 28.999999832361937, Avg Reward: 4.17\n","Episode 49, Epsilon: 0.22, Total Reward: 325.7099954849109, Steps: 11573, Max Reward: 19.919999873265624, Avg Reward: 4.02\n","Episode 50, Epsilon: 0.22, Total Reward: 256.0499940030277, Steps: 15929, Max Reward: 42.84999973885715, Avg Reward: 3.16\n","Episode 51, Epsilon: 0.21, Total Reward: 275.784994113259, Steps: 13549, Max Reward: 19.28499984368682, Avg Reward: 3.40\n","Episode 52, Epsilon: 0.21, Total Reward: 265.49499407131225, Steps: 15068, Max Reward: 33.80499979481101, Avg Reward: 3.28\n","Episode 53, Epsilon: 0.20, Total Reward: 291.81999458000064, Steps: 12863, Max Reward: 19.529999879188836, Avg Reward: 3.60\n","Episode 54, Epsilon: 0.19, Total Reward: 316.8449953077361, Steps: 11680, Max Reward: 24.489999869838357, Avg Reward: 3.91\n","Episode 55, Epsilon: 0.19, Total Reward: 73.84499047324061, Steps: 29517, Max Reward: 31.899999755434692, Avg Reward: 0.91\n","Episode 56, Epsilon: 0.18, Total Reward: 314.7099954970181, Steps: 12958, Max Reward: 24.03999986499548, Avg Reward: 3.89\n","Episode 57, Epsilon: 0.18, Total Reward: 313.8849952928722, Steps: 11683, Max Reward: 23.97999986540526, Avg Reward: 3.88\n","Episode 58, Epsilon: 0.17, Total Reward: 321.634995540604, Steps: 11975, Max Reward: 28.984999833628535, Avg Reward: 3.97\n","Episode 59, Epsilon: 0.17, Total Reward: 330.4399960124865, Steps: 12252, Max Reward: 20.069999871775508, Avg Reward: 4.08\n","Episode 60, Epsilon: 0.16, Total Reward: 195.1699933456257, Steps: 22264, Max Reward: 23.36999984551221, Avg Reward: 2.41\n","Episode 61, Epsilon: 0.16, Total Reward: 294.2349951453507, Steps: 14752, Max Reward: 23.334999836049974, Avg Reward: 3.63\n","Episode 62, Epsilon: 0.15, Total Reward: 251.44499499816447, Steps: 20371, Max Reward: 18.18999987281859, Avg Reward: 3.10\n","Episode 63, Epsilon: 0.15, Total Reward: 283.37499537784606, Steps: 16663, Max Reward: 23.989999862387776, Avg Reward: 3.50\n","Episode 64, Epsilon: 0.14, Total Reward: 351.23999627586454, Steps: 9850, Max Reward: 23.98499985318631, Avg Reward: 4.34\n","Episode 65, Epsilon: 0.14, Total Reward: 286.39499503187835, Steps: 14799, Max Reward: 28.694999833591282, Avg Reward: 3.54\n","Episode 66, Epsilon: 0.13, Total Reward: 347.06499629002064, Steps: 10828, Max Reward: 29.149999836459756, Avg Reward: 4.28\n","Episode 67, Epsilon: 0.13, Total Reward: 348.66999626439065, Steps: 10378, Max Reward: 19.4699998954311, Avg Reward: 4.30\n","Episode 68, Epsilon: 0.13, Total Reward: 280.7999952994287, Steps: 16654, Max Reward: 24.499999838881195, Avg Reward: 3.47\n","Episode 69, Epsilon: 0.12, Total Reward: 286.76999492943287, Steps: 13995, Max Reward: 27.824999833479524, Avg Reward: 3.54\n","Episode 70, Epsilon: 0.12, Total Reward: 97.49499276466668, Steps: 32868, Max Reward: 21.094999814406037, Avg Reward: 1.20\n","Episode 71, Epsilon: 0.12, Total Reward: 325.68499575089663, Steps: 11521, Max Reward: 24.184999879449606, Avg Reward: 4.02\n","Episode 72, Epsilon: 0.11, Total Reward: 291.46999537572265, Steps: 15257, Max Reward: 27.369999789632857, Avg Reward: 3.60\n","Episode 73, Epsilon: 0.11, Total Reward: 328.8849959047511, Steps: 11353, Max Reward: 20.28499989118427, Avg Reward: 4.06\n","Episode 74, Epsilon: 0.10, Total Reward: -414.5500126890838, Steps: 83571, Max Reward: 23.099999678321183, Avg Reward: -5.12\n","Episode 75, Epsilon: 0.10, Total Reward: 349.6049966085702, Steps: 11719, Max Reward: 35.10499980393797, Avg Reward: 4.32\n","Episode 76, Epsilon: 0.10, Total Reward: 49.969993928447366, Steps: 43622, Max Reward: 16.46999988052994, Avg Reward: 0.62\n","Episode 77, Epsilon: 0.10, Total Reward: 362.0899967784062, Steps: 9928, Max Reward: 20.389999894425273, Avg Reward: 4.47\n","Episode 78, Epsilon: 0.09, Total Reward: 344.3499967781827, Steps: 12435, Max Reward: 29.43499985616654, Avg Reward: 4.25\n","Episode 79, Epsilon: 0.09, Total Reward: 316.22999631240964, Steps: 15110, Max Reward: 28.374999837949872, Avg Reward: 3.90\n","Episode 80, Epsilon: 0.09, Total Reward: 345.0099964858964, Steps: 11007, Max Reward: 19.409999874420464, Avg Reward: 4.26\n","Episode 81, Epsilon: 0.08, Total Reward: 329.4599963510409, Steps: 12727, Max Reward: 23.899999861605465, Avg Reward: 4.07\n","Episode 82, Epsilon: 0.08, Total Reward: 359.939996894449, Steps: 10968, Max Reward: 25.039999878965318, Avg Reward: 4.44\n","Episode 83, Epsilon: 0.08, Total Reward: 341.37499647028744, Steps: 11737, Max Reward: 20.174999898299575, Avg Reward: 4.21\n","Episode 84, Epsilon: 0.08, Total Reward: 345.0149965379387, Steps: 11299, Max Reward: 24.099999863654375, Avg Reward: 4.26\n","Episode 85, Epsilon: 0.08, Total Reward: 353.07499646022916, Steps: 9985, Max Reward: 19.37499989103526, Avg Reward: 4.36\n","Episode 86, Epsilon: 0.07, Total Reward: 351.1449964893982, Steps: 10319, Max Reward: 21.054999874904752, Avg Reward: 4.34\n","Episode 87, Epsilon: 0.07, Total Reward: 337.1499958736822, Steps: 10026, Max Reward: 25.55999987758696, Avg Reward: 4.16\n","Episode 88, Epsilon: 0.07, Total Reward: 340.6799962958321, Steps: 11201, Max Reward: 25.309999886900187, Avg Reward: 4.21\n","Episode 89, Epsilon: 0.07, Total Reward: 361.6949967350811, Steps: 9752, Max Reward: 25.494999883696437, Avg Reward: 4.47\n","Episode 90, Epsilon: 0.06, Total Reward: 336.65499610826373, Steps: 10930, Max Reward: 23.109999859705567, Avg Reward: 4.16\n","Episode 91, Epsilon: 0.06, Total Reward: 334.6299964301288, Steps: 12264, Max Reward: 24.929999864660203, Avg Reward: 4.13\n","Episode 92, Epsilon: 0.06, Total Reward: 366.44499673042446, Steps: 8455, Max Reward: 20.444999898783863, Avg Reward: 4.52\n","Episode 93, Epsilon: 0.06, Total Reward: 305.6999966436997, Steps: 16939, Max Reward: 28.944999837316573, Avg Reward: 3.77\n","Episode 94, Epsilon: 0.06, Total Reward: 343.81499641388655, Steps: 10658, Max Reward: 23.814999856054783, Avg Reward: 4.24\n","Episode 95, Epsilon: 0.06, Total Reward: 385.21499716490507, Steps: 7289, Max Reward: 24.11499987822026, Avg Reward: 4.76\n","Episode 96, Epsilon: 0.05, Total Reward: 378.26999709941447, Steps: 8245, Max Reward: 19.769999901764095, Avg Reward: 4.67\n","Episode 97, Epsilon: 0.05, Total Reward: 331.4049967173487, Steps: 13213, Max Reward: 25.654999861493707, Avg Reward: 4.09\n","Episode 98, Epsilon: 0.05, Total Reward: 372.49999700672925, Steps: 8670, Max Reward: 29.134999863803387, Avg Reward: 4.60\n","Episode 99, Epsilon: 0.05, Total Reward: 357.049996284768, Steps: 8324, Max Reward: 19.749999885447323, Avg Reward: 4.41\n","Episode 100, Epsilon: 0.05, Total Reward: -604.6350285606459, Steps: 59911, Max Reward: 16.009999695234, Avg Reward: -7.46\n","Episode 101, Epsilon: 0.05, Total Reward: 366.7599968276918, Steps: 8436, Max Reward: 28.8299998678267, Avg Reward: 4.53\n","Episode 102, Epsilon: 0.04, Total Reward: 389.34999725036323, Steps: 6989, Max Reward: 19.92499991040677, Avg Reward: 4.81\n","Episode 103, Epsilon: 0.04, Total Reward: 379.0849970718846, Steps: 7564, Max Reward: 24.784999880939722, Avg Reward: 4.68\n","Episode 104, Epsilon: 0.04, Total Reward: 330.97499665338546, Steps: 12801, Max Reward: 25.37499985937029, Avg Reward: 4.09\n","Episode 105, Epsilon: 0.04, Total Reward: 370.5399969378486, Steps: 8518, Max Reward: 26.139999869279563, Avg Reward: 4.57\n","Episode 106, Epsilon: 0.04, Total Reward: 370.6699967905879, Steps: 7977, Max Reward: 19.869999900460243, Avg Reward: 4.58\n","Episode 107, Epsilon: 0.04, Total Reward: 380.8999970648438, Steps: 7296, Max Reward: 20.299999905750155, Avg Reward: 4.70\n","Episode 108, Epsilon: 0.04, Total Reward: 372.3099966496229, Steps: 7143, Max Reward: 30.109999855980277, Avg Reward: 4.60\n","Episode 109, Epsilon: 0.04, Total Reward: 380.6949972640723, Steps: 8169, Max Reward: 20.654999901540577, Avg Reward: 4.70\n","Episode 110, Epsilon: 0.04, Total Reward: 357.9949971549213, Steps: 10773, Max Reward: 23.894999883137643, Avg Reward: 4.42\n","Episode 111, Epsilon: 0.03, Total Reward: 363.63499718531966, Steps: 10187, Max Reward: 20.23499990813434, Avg Reward: 4.49\n","Episode 112, Epsilon: 0.03, Total Reward: 358.19499710574746, Steps: 10475, Max Reward: 24.40499989874661, Avg Reward: 4.42\n","Episode 113, Epsilon: 0.03, Total Reward: 353.8949969904497, Steps: 10646, Max Reward: 29.494999871589243, Avg Reward: 4.37\n","Episode 114, Epsilon: 0.03, Total Reward: 391.4149974193424, Steps: 6978, Max Reward: 20.714999889023602, Avg Reward: 4.83\n","Episode 115, Epsilon: 0.03, Total Reward: 383.9899972388521, Steps: 7449, Max Reward: 20.58999991323799, Avg Reward: 4.74\n","Episode 116, Epsilon: 0.03, Total Reward: 18.21499675605446, Steps: 54615, Max Reward: 20.514999890699983, Avg Reward: 0.22\n","Episode 117, Epsilon: 0.03, Total Reward: -151.00000068545341, Steps: 84546, Max Reward: 17.799999898299575, Avg Reward: -1.86\n","Episode 118, Epsilon: 0.03, Total Reward: 366.2199978698045, Steps: 12138, Max Reward: 25.31999988760799, Avg Reward: 4.52\n","Episode 119, Epsilon: 0.03, Total Reward: 350.61499777808785, Steps: 13678, Max Reward: 25.81499986536801, Avg Reward: 4.33\n","Episode 120, Epsilon: 0.03, Total Reward: 384.3249975796789, Steps: 8586, Max Reward: 30.524999856948853, Avg Reward: 4.74\n","Episode 121, Epsilon: 0.03, Total Reward: 381.5649974895641, Steps: 8668, Max Reward: 19.614999898709357, Avg Reward: 4.71\n","Episode 122, Epsilon: 0.02, Total Reward: 349.1349976370111, Steps: 13268, Max Reward: 24.83499987795949, Avg Reward: 4.31\n","Episode 123, Epsilon: 0.02, Total Reward: 378.43999725952744, Steps: 8363, Max Reward: 24.939999868161976, Avg Reward: 4.67\n","Episode 124, Epsilon: 0.02, Total Reward: 384.64499752689153, Steps: 8078, Max Reward: 20.2449999069795, Avg Reward: 4.75\n","Episode 125, Epsilon: 0.02, Total Reward: 385.8149971906096, Steps: 7073, Max Reward: 20.014999898150563, Avg Reward: 4.76\n","Episode 126, Epsilon: 0.02, Total Reward: 357.35499681625515, Steps: 9717, Max Reward: 20.2549998909235, Avg Reward: 4.41\n","Episode 127, Epsilon: 0.02, Total Reward: 371.88499720953405, Steps: 9177, Max Reward: 29.289999862201512, Avg Reward: 4.59\n","Episode 128, Epsilon: 0.02, Total Reward: 310.5349970338866, Steps: 16487, Max Reward: 23.534999896772206, Avg Reward: 3.83\n","Episode 129, Epsilon: 0.02, Total Reward: 337.0999972950667, Steps: 13970, Max Reward: 18.299999890848994, Avg Reward: 4.16\n","Episode 130, Epsilon: 0.02, Total Reward: 385.68999733403325, Steps: 7388, Max Reward: 24.889999890699983, Avg Reward: 4.76\n","Episode 131, Epsilon: 0.02, Total Reward: 384.8149971589446, Steps: 6866, Max Reward: 24.71499988157302, Avg Reward: 4.75\n","Episode 132, Epsilon: 0.02, Total Reward: 379.1499972427264, Steps: 8122, Max Reward: 20.04999989271164, Avg Reward: 4.68\n","Episode 133, Epsilon: 0.02, Total Reward: 385.30999721214175, Steps: 7022, Max Reward: 20.40999989863485, Avg Reward: 4.76\n","Early stopping at episode 134\n","Thời gian thực thi: 1587.758059 giây\n"]}]},{"cell_type":"code","source":["!python eval.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AV4N2k0EIgW5","executionInfo":{"status":"ok","timestamp":1734442345347,"user_tz":-420,"elapsed":1014164,"user":{"displayName":"Minh Khải","userId":"17162546248965680877"}},"outputId":"c9ffefae-5316-4d1a-e18d-783c956b0910"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["====================\n","Eval with random policy\n","/usr/local/lib/python3.10/dist-packages/pettingzoo/utils/conversions.py:289: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.\n","  warnings.warn(\n","  0% 0/30 [00:00<?, ?it/s]Done recording pretrained agents\n","  3% 1/30 [00:25<12:24, 25.66s/it]Done recording pretrained agents\n","  7% 2/30 [00:50<11:42, 25.09s/it]Done recording pretrained agents\n"," 10% 3/30 [00:55<07:14, 16.10s/it]Done recording pretrained agents\n"," 13% 4/30 [01:01<05:16, 12.18s/it]Done recording pretrained agents\n"," 17% 5/30 [01:09<04:26, 10.65s/it]Done recording pretrained agents\n"," 20% 6/30 [01:34<06:13, 15.56s/it]Done recording pretrained agents\n"," 23% 7/30 [02:00<07:09, 18.67s/it]Done recording pretrained agents\n"," 27% 8/30 [02:25<07:35, 20.71s/it]Done recording pretrained agents\n"," 30% 9/30 [02:30<05:33, 15.88s/it]Done recording pretrained agents\n"," 33% 10/30 [02:37<04:23, 13.18s/it]Done recording pretrained agents\n"," 37% 11/30 [02:56<04:45, 15.05s/it]Done recording pretrained agents\n"," 40% 12/30 [03:02<03:38, 12.15s/it]Done recording pretrained agents\n"," 43% 13/30 [03:10<03:04, 10.87s/it]Done recording pretrained agents\n"," 47% 14/30 [03:36<04:08, 15.50s/it]Done recording pretrained agents\n"," 50% 15/30 [03:43<03:13, 12.92s/it]Done recording pretrained agents\n"," 53% 16/30 [03:51<02:39, 11.40s/it]Done recording pretrained agents\n"," 57% 17/30 [03:56<02:02,  9.42s/it]Done recording pretrained agents\n"," 60% 18/30 [04:02<01:43,  8.60s/it]Done recording pretrained agents\n"," 63% 19/30 [04:07<01:23,  7.59s/it]Done recording pretrained agents\n"," 67% 20/30 [04:13<01:08,  6.87s/it]Done recording pretrained agents\n"," 70% 21/30 [04:37<01:49, 12.15s/it]Done recording pretrained agents\n"," 73% 22/30 [04:44<01:25, 10.68s/it]Done recording pretrained agents\n"," 77% 23/30 [04:49<01:02,  8.90s/it]Done recording pretrained agents\n"," 80% 24/30 [05:14<01:22, 13.74s/it]Done recording pretrained agents\n"," 83% 25/30 [05:19<00:54, 10.96s/it]Done recording pretrained agents\n"," 87% 26/30 [05:26<00:39,  9.80s/it]Done recording pretrained agents\n"," 90% 27/30 [05:31<00:25,  8.39s/it]Done recording pretrained agents\n"," 93% 28/30 [05:56<00:26, 13.34s/it]Done recording pretrained agents\n"," 97% 29/30 [06:05<00:12, 12.26s/it]Done recording pretrained agents\n","100% 30/30 [06:30<00:00, 13.02s/it]\n","{'winrate_red': 0.0, 'winrate_blue': 1.0, 'average_rewards_red': -1.1547387255026114, 'average_rewards_blue': 4.08111108035815}\n","====================\n","Eval with trained policy\n","/usr/local/lib/python3.10/dist-packages/pettingzoo/utils/conversions.py:289: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.\n","  warnings.warn(\n","  0% 0/30 [00:00<?, ?it/s]Done recording pretrained agents\n","  3% 1/30 [00:04<02:04,  4.30s/it]Done recording pretrained agents\n","  7% 2/30 [00:08<02:03,  4.41s/it]Done recording pretrained agents\n"," 10% 3/30 [00:13<02:00,  4.46s/it]Done recording pretrained agents\n"," 13% 4/30 [00:17<01:53,  4.38s/it]Done recording pretrained agents\n"," 17% 5/30 [00:21<01:46,  4.28s/it]Done recording pretrained agents\n"," 20% 6/30 [00:26<01:48,  4.53s/it]Done recording pretrained agents\n"," 23% 7/30 [00:31<01:45,  4.60s/it]Done recording pretrained agents\n"," 27% 8/30 [00:35<01:35,  4.35s/it]Done recording pretrained agents\n"," 30% 9/30 [00:38<01:27,  4.15s/it]Done recording pretrained agents\n"," 33% 10/30 [00:43<01:27,  4.40s/it]Done recording pretrained agents\n"," 37% 11/30 [00:47<01:19,  4.19s/it]Done recording pretrained agents\n"," 40% 12/30 [00:51<01:14,  4.13s/it]Done recording pretrained agents\n"," 43% 13/30 [00:56<01:14,  4.37s/it]Done recording pretrained agents\n"," 47% 14/30 [01:00<01:06,  4.15s/it]Done recording pretrained agents\n"," 50% 15/30 [01:03<01:00,  4.02s/it]Done recording pretrained agents\n"," 53% 16/30 [01:09<01:01,  4.37s/it]Done recording pretrained agents\n"," 57% 17/30 [01:13<00:56,  4.32s/it]Done recording pretrained agents\n"," 60% 18/30 [01:17<00:50,  4.23s/it]Done recording pretrained agents\n"," 63% 19/30 [01:21<00:47,  4.27s/it]Done recording pretrained agents\n"," 67% 20/30 [01:26<00:43,  4.32s/it]Done recording pretrained agents\n"," 70% 21/30 [01:30<00:38,  4.27s/it]Done recording pretrained agents\n"," 73% 22/30 [01:34<00:34,  4.34s/it]Done recording pretrained agents\n"," 77% 23/30 [01:39<00:31,  4.49s/it]Done recording pretrained agents\n"," 80% 24/30 [01:43<00:25,  4.29s/it]Done recording pretrained agents\n"," 83% 25/30 [01:49<00:23,  4.72s/it]Done recording pretrained agents\n"," 87% 26/30 [01:54<00:19,  4.97s/it]Done recording pretrained agents\n"," 90% 27/30 [01:59<00:14,  4.86s/it]Done recording pretrained agents\n"," 93% 28/30 [02:03<00:09,  4.62s/it]Done recording pretrained agents\n"," 97% 29/30 [02:08<00:04,  4.71s/it]Done recording pretrained agents\n","100% 30/30 [02:12<00:00,  4.40s/it]\n","{'winrate_red': 0.0, 'winrate_blue': 1.0, 'average_rewards_red': 2.013257184072777, 'average_rewards_blue': 4.965415608192269}\n","====================\n","Eval with final trained policy\n","  0% 0/30 [00:00<?, ?it/s]Done recording pretrained agents\n","  3% 1/30 [00:09<04:33,  9.45s/it]Done recording pretrained agents\n","  7% 2/30 [00:29<07:11, 15.43s/it]Done recording pretrained agents\n"," 10% 3/30 [00:50<08:10, 18.17s/it]Done recording pretrained agents\n"," 13% 4/30 [01:02<06:51, 15.85s/it]Done recording pretrained agents\n"," 17% 5/30 [01:22<07:10, 17.23s/it]Done recording pretrained agents\n"," 20% 6/30 [01:35<06:15, 15.64s/it]Done recording pretrained agents\n"," 23% 7/30 [01:52<06:15, 16.33s/it]Done recording pretrained agents\n"," 27% 8/30 [02:12<06:26, 17.57s/it]Done recording pretrained agents\n"," 30% 9/30 [02:33<06:25, 18.35s/it]Done recording pretrained agents\n"," 33% 10/30 [02:53<06:16, 18.85s/it]Done recording pretrained agents\n"," 37% 11/30 [03:04<05:16, 16.65s/it]Done recording pretrained agents\n"," 40% 12/30 [03:24<05:17, 17.64s/it]Done recording pretrained agents\n"," 43% 13/30 [03:42<05:03, 17.87s/it]Done recording pretrained agents\n"," 47% 14/30 [03:55<04:21, 16.35s/it]Done recording pretrained agents\n"," 50% 15/30 [04:13<04:10, 16.72s/it]Done recording pretrained agents\n"," 53% 16/30 [04:22<03:22, 14.43s/it]Done recording pretrained agents\n"," 57% 17/30 [04:39<03:16, 15.08s/it]Done recording pretrained agents\n"," 60% 18/30 [04:53<02:56, 14.73s/it]Done recording pretrained agents\n"," 63% 19/30 [05:08<02:43, 14.82s/it]Done recording pretrained agents\n"," 67% 20/30 [05:25<02:34, 15.47s/it]Done recording pretrained agents\n"," 70% 21/30 [05:38<02:14, 14.99s/it]Done recording pretrained agents\n"," 73% 22/30 [05:59<02:12, 16.60s/it]Done recording pretrained agents\n"," 77% 23/30 [06:19<02:04, 17.73s/it]Done recording pretrained agents\n"," 80% 24/30 [06:39<01:50, 18.37s/it]Done recording pretrained agents\n"," 83% 25/30 [06:49<01:18, 15.78s/it]Done recording pretrained agents\n"," 87% 26/30 [07:08<01:07, 16.77s/it]Done recording pretrained agents\n"," 90% 27/30 [07:19<00:45, 15.22s/it]Done recording pretrained agents\n"," 93% 28/30 [07:40<00:33, 16.76s/it]Done recording pretrained agents\n"," 97% 29/30 [07:56<00:16, 16.56s/it]Done recording pretrained agents\n","100% 30/30 [08:07<00:00, 16.25s/it]\n","{'winrate_red': 0.0, 'winrate_blue': 1.0, 'average_rewards_red': 2.3387839335829423, 'average_rewards_blue': 4.206880624988595}\n","====================\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"z5cD2XvbU897"},"execution_count":null,"outputs":[]}]}